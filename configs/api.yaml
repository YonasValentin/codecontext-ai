model:
  base_model: "Qwen/Qwen3-8B"
  model_name: "codecontext-api-qwen3-8b"
  task_type: "api"
  
training:
  num_epochs: 4
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 1.5e-4
  weight_decay: 0.01
  warmup_steps: 150
  
  lora_r: 64
  lora_alpha: 128
  lora_dropout: 0.1
  lora_target_modules:
    - "q_proj"
    - "k_proj" 
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  
  use_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_quant_type: "nf4"
  use_nested_quant: true
  
  optimizer: "adamw_torch"
  lr_scheduler_type: "cosine"
  max_grad_norm: 1.0
  
  gradient_checkpointing: true
  dataloader_pin_memory: false
  remove_unused_columns: false

data:
  train_file: "data/api_train.jsonl"
  eval_file: "data/api_eval.jsonl"
  max_seq_length: 2048
  truncation: true
  padding: false
  
  instruction_template: |
    ### Instruction:
    Generate comprehensive API documentation for the following code:
    
    ### Code Context:
    {code_context}
    
    ### API Endpoints:
    {api_endpoints}
    
    ### Models/Schemas:
    {data_models}
    
    ### Requirements:
    - Clear endpoint descriptions with HTTP methods
    - Request/response schemas with examples
    - Authentication requirements
    - Error codes and responses
    - Rate limiting information
    - Professional OpenAPI-style formatting
    
    ### API Documentation:
  
  response_template: |
    {api_documentation}

evaluation:
  eval_steps: 100
  eval_strategy: "steps"
  per_device_eval_batch_size: 2
  evaluation_strategy: "steps"
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  early_stopping_patience: 3
  early_stopping_threshold: 0.001

logging:
  logging_steps: 10
  logging_strategy: "steps"
  report_to: "wandb"
  run_name: "codecontext-api-qwen3-8b"
  wandb_project: "codecontext-ai"
  wandb_entity: null

output:
  output_dir: "./models/codecontext-api-qwen3-8b"
  save_steps: 250
  save_strategy: "steps"
  save_total_limit: 3
  push_to_hub: false
  hub_model_id: "codecontext/codecontext-api-qwen3-8b"
  hub_private_repo: false

hardware:
  bf16: false
  fp16: true
  tf32: true
  dataloader_num_workers: 4
  max_memory_MB: 24000

seed: 42
data_seed: 42

advanced:
  remove_unused_columns: false
  label_names: ["labels"]
  torch_compile: false
  use_rslora: false
  use_dora: false
  max_steps: -1
  label_smoothing_factor: 0.0